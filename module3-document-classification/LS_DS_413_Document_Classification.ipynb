{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Prepare)\n",
    "\n",
    "Today's guided module project will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills. The competition will begin\n",
    "\n",
    "## Learning Objectives\n",
    "* <a href=\"#p0\">Part 0</a>: Kaggle Competition\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pieplines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Sklearn pipelines allow you to stitch together multiple components of a machine learning process. The idea is that you can pass you raw data and get predictions out of the pipeline. This ability to pass raw input and receive a prediction from a singular class makes pipelines well suited for production, because you can pickle a a pipeline without worry about other data preprocessing steps. \n",
    "\n",
    "*Note:* Each time we call the pipeline during grid search, each component is fit again. The vectorizer (tf-idf) is transforming our entire vocabulary during each cross-validation fold. That transformation adds significant run time to our grid search. There *might* be interactions between the vectorizer and our classifier, so we estimate their performance together in the code below. However, if your goal is to reduce run time. Train your vectorizer separately (ie out of the grid-searched pipeline). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism',\n",
    "              'talk.religion.misc']\n",
    "\n",
    "data = fetch_20newsgroups(subset='train', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline Components\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pipeline\n",
    "pipe = Pipeline([\n",
    "                 #Vectorizer\n",
    "                 ('vect', vect),\n",
    "                 # Classifier\n",
    "                 ('clf', rfc)\n",
    "                ])\n",
    "\n",
    "# The pipeline puts together a bunch fit then transform,fit then predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:   52.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': (0.69, 1.0), 'vect__min_df': (0.02, 0.06), 'vect__max_features': (400, 1300), 'clf__n_estimators': (5, 28), 'clf__max_depth': (12, 24)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': ( 0.69, 1.0),\n",
    "    'vect__min_df': (.02, .06),\n",
    "    'vect__max_features': (400,1300),\n",
    "    'clf__n_estimators':(5, 28,),\n",
    "    'clf__max_depth':(12,24)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9054842473745625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.predict(['Send me lots of money now', 'you won the lottery in Nigeria'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipe1 = Pipeline([('vect', vect), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A marriage of 13 and 18 year old bourbons. A m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>There have been some legendary Bowmores from t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>This bottling celebrates master distiller Park...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>What impresses me most is how this whisky evol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>A caramel-laden fruit bouquet, followed by une...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        description  category\n",
       "0   1  A marriage of 13 and 18 year old bourbons. A m...         2\n",
       "1   2  There have been some legendary Bowmores from t...         1\n",
       "2   3  This bottling celebrates master distiller Park...         2\n",
       "3   4  What impresses me most is how this whisky evol...         1\n",
       "4   9  A caramel-laden fruit bouquet, followed by une...         2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=4)]: Done 160 out of 160 | elapsed:   25.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'vect__max_df': (0.69, 1.0), 'vect__min_df': (0.02, 0.069), 'vect__max_features': (400, 1400), 'clf__n_estimators': (5, 35), 'clf__max_depth': (12, 30)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters1 = {\n",
    "    'vect__max_df': ( 0.69, 1.0),\n",
    "    'vect__min_df': (.02, .069),\n",
    "    'vect__max_features': (400,1400),\n",
    "    'clf__n_estimators':(5, 35),\n",
    "    'clf__max_depth':(12,30)\n",
    "}\n",
    "\n",
    "grid_search1 = GridSearchCV(pipe1,parameters1, cv=5, n_jobs=4, verbose=1)\n",
    "grid_search1.fit(train.description, train.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8882443928847641"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this compeition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search1.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'category':pred})\n",
    "submission['category'] = submission['category'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    200\n",
       "2     40\n",
       "3     33\n",
       "4     15\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "submission.to_csv('./data/submission4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achienve 90% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, # Just here for demo. \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "    'lsi__svd__n_components': [10,100,250],\n",
    "    'lsi__vect__max_df':[.9, .95, 1.0],\n",
    "    'clf__n_estimators':[5,10,20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSI\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "\n",
    "# Pipe\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('lsi', Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm=...obs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done 135 out of 135 | elapsed:  8.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('lsi', Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm=...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'lsi__svd__n_components': [10, 100, 250], 'lsi__vect__max_df': [0.9, 0.95, 1.0], 'clf__n_estimators': (5, 10, 20)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "grid_search = GridSearchCV(pipe,params, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8844807467911319"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2070,), dtype=int32).\n",
      "Pickling array (shape=(516,), dtype=int32).\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2070,), dtype=int32).\n",
      "Pickling array (shape=(516,), dtype=int32).\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    6.3s\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    6.3s\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2070,), dtype=int32).\n",
      "Pickling array (shape=(516,), dtype=int32).\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    6.5s\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    6.8s\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2070,), dtype=int32).\n",
      "Pickling array (shape=(516,), dtype=int32).\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    7.1s\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  1.0min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  1.1min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2070,), dtype=int32).\n",
      "Pickling array (shape=(516,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  1.3min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.3min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:  1.3min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.3min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.3min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2070,), dtype=int32).\n",
      "Pickling array (shape=(516,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.3min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:  1.4min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  1.4min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  1.6min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:  1.7min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2070,), dtype=int32).\n",
      "Pickling array (shape=(516,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:  1.9min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.9min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.1min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  2.2min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:  2.3min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2070,), dtype=int32).\n",
      "Pickling array (shape=(516,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.5min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  2.6min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  2.8min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:  3.7min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  3.7min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2070,), dtype=int32).\n",
      "Pickling array (shape=(516,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.9min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.1min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:  4.3min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:  4.4min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  4.4min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2070,), dtype=int32).\n",
      "Pickling array (shape=(516,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  60 | elapsed:  4.4min remaining:  2.6min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  60 | elapsed:  4.5min remaining:  2.4min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  60 | elapsed:  4.5min remaining:  2.2min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  60 | elapsed:  4.5min remaining:  2.1min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  60 | elapsed:  4.5min remaining:  1.9min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2070,), dtype=int32).\n",
      "Pickling array (shape=(516,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  60 | elapsed:  4.6min remaining:  1.8min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  60 | elapsed:  4.6min remaining:  1.7min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2068,), dtype=int32).\n",
      "Pickling array (shape=(518,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  60 | elapsed:  4.7min remaining:  1.6min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  60 | elapsed:  4.8min remaining:  1.5min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2069,), dtype=int32).\n",
      "Pickling array (shape=(517,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  60 | elapsed:  5.3min remaining:  1.5min\n",
      "Pickling array (shape=(2586,), dtype=object).\n",
      "Pickling array (shape=(2586,), dtype=int64).\n",
      "Pickling array (shape=(2070,), dtype=int32).\n",
      "Pickling array (shape=(516,), dtype=int32).\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  60 | elapsed:  5.6min remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of  60 | elapsed:  5.6min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  60 | elapsed:  5.6min remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of  60 | elapsed:  7.6min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  60 | elapsed:  7.7min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  60 | elapsed:  7.7min remaining:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  60 | elapsed:  7.7min remaining:   51.4s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  60 | elapsed:  7.7min remaining:   42.0s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  60 | elapsed:  7.7min remaining:   33.1s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of  60 | elapsed:  7.7min remaining:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of  60 | elapsed:  7.7min remaining:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  7.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  7.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('lsi', Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm=...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'lsi__svd__n_components': [10, 100, 250], 'lsi__vect__max_df': [0.69, 1.0], 'clf__n_estimators': [5, 28]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=100)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'lsi__svd__n_components': [10,100,250],\n",
    "    'lsi__vect__max_df':  [0.69, 1.0],\n",
    "    'clf__n_estimators':[5, 28]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=100)\n",
    "grid_search.fit(train.description, train.category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* You are only allowed two submissions a day. Only submit if you feel you cannot achieve higher test accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'category':pred})\n",
    "submission['category'] = submission['category'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>955</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3532</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  category\n",
       "0   955         2\n",
       "1  3532         2\n",
       "2  1390         1\n",
       "3  1024         1\n",
       "4  1902         1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8905645784996133"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Two bananas in pyjamas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "bananas_vector = doc.vector\n",
    "print(len(bananas_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = get_word_vectors(data.data)\n",
    "\n",
    "len(X) == len(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathansokoll/anaconda3/envs/U4-S1-NLP-DS6/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9883313885647608"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X, data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to your Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "To review this module: \n",
    "* Continue working on the Kaggle comeptition\n",
    "* Find another text classification task to work on"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
